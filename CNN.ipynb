{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoomRooms/2023BigData/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "y8uiXujUrNqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/BigData/csv"
      ],
      "metadata": {
        "id": "x5VbzYInrxV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_tabnet"
      ],
      "metadata": {
        "id": "78KD-O6Eh3AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 저장할 빈 데이터프레임 생성\n",
        "all_data = pd.DataFrame()\n",
        "filename = ['10-Rbot-20110818.binetflow.parquet', '4-Rbot-20110815.binetflow.parquet', '11-Rbot-20110818-2.binetflow.parquet', '5-Virut-20110815-2.binetflow.parquet', '12-NsisAy-20110819.binetflow.parquet', '6-Menti-20110816.binetflow.parquet', '13-Virut-20110815-3.binetflow.parquet', '7-Sogou-20110816-2.binetflow.parquet', '1-Neris-20110810.binetflow.parquet', '8-Murlo-20110816-3.binetflow.parquet', '2-Neris-20110811.binetflow.parquet', '9-Neris-20110817.binetflow.parquet', '3-Rbot-20110812.binetflow.parquet']\n",
        "\n",
        "# 13개의 parquet 파일 순회\n",
        "for file_path in filename:\n",
        "    # parquet 파일 로드\n",
        "    df = pd.read_parquet(file_path)\n",
        "    \n",
        "    # 데이터 프레임 연결\n",
        "    all_data = pd.concat([all_data, df], ignore_index=True)"
      ],
      "metadata": {
        "id": "uWXo257y0XCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NaN Drop\n",
        "all_data = all_data.dropna()\n",
        "all_data.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "ObOrtoMTBKnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "tmp = pd.DataFrame()\n",
        "tmp['encode'] = label_encoder.fit_transform(all_data['label'])\n",
        "tmp['label'] = all_data['label']\n",
        "print(tmp.columns)"
      ],
      "metadata": {
        "id": "LWNQu1de_t6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en = []\n",
        "la = []\n",
        "for encode, label in tmp.values:\n",
        "    if('flow=From-Botnet' in label):\n",
        "        en.append(encode)\n",
        "        la.append(label)"
      ],
      "metadata": {
        "id": "T_mZ5i9rAnAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp2 = pd.DataFrame({'Encode' : en, 'Label':la})"
      ],
      "metadata": {
        "id": "t3vAeqncCgW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls_bot = list(tmp2['Encode'].unique())"
      ],
      "metadata": {
        "id": "0tAlw3upDw-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoder 생성 및 적용\n",
        "label_encoder = LabelEncoder()\n",
        "all_data['proto'] = label_encoder.fit_transform(all_data['proto'])\n",
        "all_data['dir'] = label_encoder.fit_transform(all_data['dir'])\n",
        "all_data['state'] = label_encoder.fit_transform(all_data['state'])\n",
        "all_data['Family'] = label_encoder.fit_transform(all_data['Family'])\n",
        "all_data['label'] = label_encoder.fit_transform(all_data['label'])\n",
        "\n",
        "all_data['target'] = None"
      ],
      "metadata": {
        "id": "I28nUleJH1ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "for label in all_data['label']:\n",
        "    if label in ls_bot:\n",
        "        all_data.loc[count, 'target'] = 1\n",
        "    else:\n",
        "        all_data.loc[count, 'target'] = 0\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "WKkWWOJbIGpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 데이터와 출력 데이터 분리\n",
        "X = all_data[['dur', 'proto', 'dir', 'state', 'stos', 'dtos', 'tot_pkts', 'tot_bytes', 'src_bytes', 'Family', 'label']]\n",
        "Y = all_data['target']\n",
        "\n",
        "# Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "Y = label_encoder.fit_transform(Y)\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 분리\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 검증 데이터 분리\n",
        "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "60uuHGdo3H8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TabNet 모델 생성 및 학습\n",
        "model = TabNetClassifier()\n",
        "model.fit(train_X.values, train_Y, eval_set=[(val_X.values, val_Y)])"
      ],
      "metadata": {
        "id": "-dA1H58M0gbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 예측\n",
        "preds = model.predict(test_X.values)"
      ],
      "metadata": {
        "id": "hne_Ct9u7-yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, f1_score, accuracy_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "bNZgw98X8k42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 지표 계산\n",
        "f1 = f1_score(test_Y, preds)\n",
        "accuracy = accuracy_score(test_Y, preds)\n",
        "\n",
        "# 분류 보고서 출력\n",
        "report = classification_report(test_Y, preds)\n",
        "print(report)\n",
        "\n",
        "# ROC Curve 계산\n",
        "fpr, tpr, _ = roc_curve(test_Y, preds)\n",
        "auc = roc_auc_score(test_Y, preds)\n",
        "\n",
        "# Precision-Recall Curve 계산\n",
        "precision, recall, _ = precision_recall_curve(test_Y, preds)\n",
        "\n",
        "# 성능 지표 출력\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"AUC: {auc}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# ROC Curve 시각화\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label='ROC Curve (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve 시각화\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label='Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-d0BdobDiCnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnmmGXSRwBD6"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "fns = []\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         fns.append(os.path.join(dirname, filename))\n",
        "# print(fns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scapy.all import rdpcap, Ether, ARP, TCP, UDP, ICMP\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ],
      "metadata": {
        "id": "bKoMH-tBiqK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "packets = rdpcap('./1/botnet-capture-20110810-neris.pcap')"
      ],
      "metadata": {
        "id": "F7-xjBqSkB0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./1/capture20110810.binetflow')"
      ],
      "metadata": {
        "id": "zJ2rZ0k0knFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(packets)"
      ],
      "metadata": {
        "id": "NL4B34JDlAej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for packet in packets:\n",
        "    if(count>50):\n",
        "        break\n",
        "    print(packet)\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "stVl9UP4kuJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for packet in packets:\n",
        "    if(count>5):\n",
        "        break\n",
        "    print(packet[IP])\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "_qlLSSGqmxmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd csv"
      ],
      "metadata": {
        "id": "OM0VAzwFo38K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "BktVZKu6o7LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dirname, _, filenames in os.walk(\"./\"):\n",
        "    for filename in filenames:\n",
        "        fns.append(os.path.join(dirname, filename))\n",
        "print(fns)"
      ],
      "metadata": {
        "id": "BxzUfWoEyGJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score, accuracy_score\n",
        "from fastcore.basics import *\n",
        "from fastcore.parallel import *\n",
        "from os import cpu_count\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qhjhqPDn0F0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(objs=[\n",
        "    pd.read_parquet(fns[0])], copy=False, sort=False)"
      ],
      "metadata": {
        "id": "V0DPtN5wpHhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.label.value_counts().head(10)"
      ],
      "metadata": {
        "id": "mzOG50n9qHTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['dir']"
      ],
      "metadata": {
        "id": "a0V1QJG3pRkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(objs=[\n",
        "    pd.read_parquet(f) for f in fns\n",
        "], copy=False, sort=False)\n",
        "df.shape, df.columns"
      ],
      "metadata": {
        "id": "PkxqjALu0Hdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "OdeZIjes1CHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ###############################\n",
        "        ########## 문제 3-1 ############\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(32)\n",
        "        self.conv1_2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1_2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 94, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(94)\n",
        "        self.conv2_2 = nn.Conv2d(94, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 192, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(192)\n",
        "        self.conv3_2 = nn.Conv2d(192, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 320, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(320)\n",
        "        self.conv4_2 = nn.Conv2d(320, 384, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_2 = nn.BatchNorm2d(384)\n",
        "        self.conv4_3 = nn.Conv2d(384, 448, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_3 = nn.BatchNorm2d(448)\n",
        "        self.conv4_4 = nn.Conv2d(448, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_4 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(512 * 1 * 1, 500)\n",
        "        self.fc2 = nn.Linear(500, 100)\n",
        "        self.fc3 = nn.Linear(100, 10)\n",
        "\n",
        "        ###############################\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "        x = F.relu(self.pool(self.bn1_2(self.conv1_2(x))))\n",
        "\n",
        "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = F.relu(self.pool(self.bn2_2(self.conv2_2(x))))\n",
        "\n",
        "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "        x = F.relu(self.pool(self.bn3_2(self.conv3_2(x))))\n",
        "\n",
        "        x = F.relu(self.bn4_1(self.conv4_1(x)))\n",
        "        x = F.relu(self.bn4_2(self.conv4_2(x)))\n",
        "        x = F.relu(self.bn4_3(self.conv4_3(x)))\n",
        "        x = F.relu(self.pool(self.bn4_4(self.conv4_4(x))))\n",
        "        \n",
        "        x = torch.nn.Flatten()(x) # flatten all dimensions except batch\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = CNN()"
      ],
      "metadata": {
        "id": "duwrjNRS04IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "hk7oXlPG24U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rnn_model(input_shape):\n",
        "    # 입력 레이어 정의\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # RNN 레이어 정의\n",
        "    rnn_layer = LSTM(64)(inputs)\n",
        "\n",
        "    # 출력 레이어 정의\n",
        "    outputs = Dense(1, activation='sigmoid')(rnn_layer)\n",
        "\n",
        "    # 모델 생성\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "WUbjEehj3Dcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df.isna().sum(axis=0))"
      ],
      "metadata": {
        "id": "UjPPOfFr5gW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].astype(dtype='object')\n",
        "df['label'] = df['label'].str.startswith('flow=From-Botnet', na=False)\n",
        "df['label'] = df['label'].astype(dtype='float32', copy=False)\n",
        "df.label.value_counts().head(10)"
      ],
      "metadata": {
        "id": "UINrX0KU4y3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Family'])\n",
        "df.shape"
      ],
      "metadata": {
        "id": "dUcyX4hp495V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df.isna().sum(axis=0))"
      ],
      "metadata": {
        "id": "ewwuLT9T5sTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head"
      ],
      "metadata": {
        "id": "SlW6Dks85yWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['proto'] = df['proto'].astype('category').cat.codes\n",
        "df['proto'] = df['proto'].astype(np.int32)\n",
        "df['dir'] = df['dir'].astype('category').cat.codes\n",
        "df['dir'] = df['dir'].astype(np.int32)\n",
        "df['state'] = df['state'].astype('category').cat.codes\n",
        "df['state'] = df['state'].astype(np.int32)"
      ],
      "metadata": {
        "id": "DhdO0lpG5Bzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum(axis=0)"
      ],
      "metadata": {
        "id": "GRc0r2ds5Ch2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df.sample(frac=0.2, replace = False)\n",
        "df_train = df.drop(index = df_test.index)"
      ],
      "metadata": {
        "id": "IiXs266W3OhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_Y = df_test['label']\n",
        "test_X = df_test.drop('label', axis=1)\n",
        "train_Y = df_train['label']\n",
        "train_X = df_train.drop('label', axis=1)"
      ],
      "metadata": {
        "id": "mLKvdKK43fjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "id": "xoN81SGs7Urc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 데이터의 shape 정의\n",
        "timesteps = 9  # 시간 단계 수\n",
        "input_dim = 9  # 입력의 차원\n",
        "\n",
        "# 입력 레이어 정의\n",
        "inputs = Input(shape=(timesteps, input_dim))\n",
        "\n",
        "# LSTM 레이어 정의\n",
        "lstm_units = 32  # LSTM의 출력 차원 수\n",
        "lstm = LSTM(units=lstm_units)(inputs)\n",
        "\n",
        "# 출력 레이어 정의\n",
        "output_units = 1  # 출력의 차원 수\n",
        "outputs = Dense(units=output_units, activation='sigmoid')(lstm)  # 분류 문제의 경우 units는 클래스 수\n",
        "\n",
        "# 모델 생성\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# 모델 요약 정보 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0huPd_Uk3FQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 입력 데이터 reshape\n",
        "train_X_reshaped = np.expand_dims(train_X, axis=2)  # 입력 데이터의 차원을 3D로 변경\n",
        "\n",
        "# 모델 학습\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "model.fit(train_X_reshaped, train_Y, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# 예측 데이터 reshape\n",
        "test_X_reshaped = np.expand_dims(test_X, axis=2)  # 예측 데이터의 차원을 3D로 변경\n",
        "\n",
        "# 모델 예측\n",
        "y_pred = model.predict(test_X_reshaped)"
      ],
      "metadata": {
        "id": "_X8APBSy87kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataloader:\n",
        "    print(batch[0])"
      ],
      "metadata": {
        "id": "sqy-txxfzcY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df.sample(frac=0.2, replace = False)\n",
        "df_train = df.drop(index = df_test.index)\n",
        "df_train.shape, df_test.shape"
      ],
      "metadata": {
        "id": "zggo_fKP26dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.005)\n",
        "\n",
        "net = net.to(device) # device로 Network 전송\n",
        "print(net) # 모델 구조 확인"
      ],
      "metadata": {
        "id": "n5RZ_MRV75it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "metadata": {
        "id": "TXAI2GbL8Ynw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(df_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(df_test, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "y4vrg7L58Mxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_test.shape)"
      ],
      "metadata": {
        "id": "BvmQsPihqbLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_epochs = 5\n",
        "for epoch in range(training_epochs): # training_epochs 수만큼 반복\n",
        "    avg_loss = 0\n",
        "    for X_train, target in df_train:\n",
        "        pred = net(X_train) # \n",
        "        optimizer.zero_grad() \n",
        "        loss = criterion(pred, target) # Model output과 target 비교\n",
        "        loss.backward() # gradient 계산\n",
        "        optimizer.step() # parameter 업데이트\n",
        "        avg_loss += loss / len(train_loader) \n",
        "    print('[Epoch: {:>3}] loss = {:>.9}'.format(epoch + 1, avg_loss))\n",
        " "
      ],
      "metadata": {
        "id": "GzKWciLwpXxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in train_loader:\n",
        "    print(X, y)"
      ],
      "metadata": {
        "id": "SRNGrRgU9bK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS): # epochs수만큼 반복\n",
        "    avg_loss = 0\n",
        "    for data, target in train_loader:\n",
        "        # print(data.shape)\n",
        "        data = data.cuda() # 데이터도 gpu로 보내야함\n",
        "        target = target.cuda()\n",
        "        pred = net(data) # \n",
        "        # print(pred)\n",
        "        optimizer.zero_grad() \n",
        "        loss = criterion(pred, target) # Model output과 target 비교\n",
        "        loss.backward() # gradient 계산\n",
        "        optimizer.step() # parameter 업데이트\n",
        "        avg_loss += loss / len(train_loader) \n",
        "    print('[Epoch: {:>4}] loss = {:>.9}'.format(epoch + 1, avg_loss))"
      ],
      "metadata": {
        "id": "Vuh_8ukn79iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.index)"
      ],
      "metadata": {
        "id": "6e8pjGzpAHWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader.index)"
      ],
      "metadata": {
        "id": "KF0R_zg8CEUj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}