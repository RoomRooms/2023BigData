{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXhJWxFj0jzt/B9Z/a3+tl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoomRooms/2023BigData/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnmmGXSRwBD6"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "fns = []\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        fns.append(os.path.join(dirname, filename))\n",
        "print(fns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score, accuracy_score\n",
        "from fastcore.basics import *\n",
        "from fastcore.parallel import *\n",
        "from os import cpu_count\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qhjhqPDn0F0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(objs=[\n",
        "    pd.read_parquet(f) for f in fns\n",
        "], copy=False, sort=False)\n",
        "df.shape, df.columns"
      ],
      "metadata": {
        "id": "PkxqjALu0Hdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "OdeZIjes1CHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ###############################\n",
        "        ########## 문제 3-1 ############\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(32)\n",
        "        self.conv1_2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1_2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 94, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(94)\n",
        "        self.conv2_2 = nn.Conv2d(94, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 192, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(192)\n",
        "        self.conv3_2 = nn.Conv2d(192, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 320, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(320)\n",
        "        self.conv4_2 = nn.Conv2d(320, 384, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_2 = nn.BatchNorm2d(384)\n",
        "        self.conv4_3 = nn.Conv2d(384, 448, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_3 = nn.BatchNorm2d(448)\n",
        "        self.conv4_4 = nn.Conv2d(448, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_4 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(512 * 1 * 1, 500)\n",
        "        self.fc2 = nn.Linear(500, 100)\n",
        "        self.fc3 = nn.Linear(100, 10)\n",
        "\n",
        "        ###############################\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "        x = F.relu(self.pool(self.bn1_2(self.conv1_2(x))))\n",
        "\n",
        "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = F.relu(self.pool(self.bn2_2(self.conv2_2(x))))\n",
        "\n",
        "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "        x = F.relu(self.pool(self.bn3_2(self.conv3_2(x))))\n",
        "\n",
        "        x = F.relu(self.bn4_1(self.conv4_1(x)))\n",
        "        x = F.relu(self.bn4_2(self.conv4_2(x)))\n",
        "        x = F.relu(self.bn4_3(self.conv4_3(x)))\n",
        "        x = F.relu(self.pool(self.bn4_4(self.conv4_4(x))))\n",
        "        \n",
        "        x = torch.nn.Flatten()(x) # flatten all dimensions except batch\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = CNN()"
      ],
      "metadata": {
        "id": "duwrjNRS04IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df.sample(frac=0.2, replace = False)\n",
        "df_train = df.drop(index = df_test.index)\n",
        "df_train.shape, df_test.shape"
      ],
      "metadata": {
        "id": "zggo_fKP26dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.005)\n",
        "\n",
        "net = net.to(device) # device로 Network 전송\n",
        "print(net) # 모델 구조 확인"
      ],
      "metadata": {
        "id": "n5RZ_MRV75it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "metadata": {
        "id": "TXAI2GbL8Ynw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(df_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(df_test, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "y4vrg7L58Mxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in train_loader:\n",
        "    print(X, y)"
      ],
      "metadata": {
        "id": "SRNGrRgU9bK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS): # epochs수만큼 반복\n",
        "    avg_loss = 0\n",
        "    for data, target in train_loader:\n",
        "        # print(data.shape)\n",
        "        data = data.cuda() # 데이터도 gpu로 보내야함\n",
        "        target = target.cuda()\n",
        "        pred = net(data) # \n",
        "        # print(pred)\n",
        "        optimizer.zero_grad() \n",
        "        loss = criterion(pred, target) # Model output과 target 비교\n",
        "        loss.backward() # gradient 계산\n",
        "        optimizer.step() # parameter 업데이트\n",
        "        avg_loss += loss / len(train_loader) \n",
        "    print('[Epoch: {:>4}] loss = {:>.9}'.format(epoch + 1, avg_loss))"
      ],
      "metadata": {
        "id": "Vuh_8ukn79iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.index)"
      ],
      "metadata": {
        "id": "6e8pjGzpAHWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader.index)"
      ],
      "metadata": {
        "id": "KF0R_zg8CEUj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}